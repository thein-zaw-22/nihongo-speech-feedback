# Copy this file to .env and fill in values as needed

# Common
SECRET_KEY=dev-secret-key-change-me
DEBUG=True

# Choose one LLM provider: openai or bedrock
LLM_PROVIDER=openai

# --- OpenAI (default if LLM_PROVIDER=openai) ---
#OPENAI_API_KEY=sk-...

# --- Amazon Bedrock (set LLM_PROVIDER=bedrock) ---
#AWS_REGION_NAME=us-east-1
#AWS_ACCESS_KEY_ID=...
#AWS_SECRET_ACCESS_KEY=...
#AWS_SESSION_TOKEN=...        # optional (STS/temp creds)

# Inference profile (required for Nova; app expects a profile for Bedrock)
# Set either the full ARN or the profile ID for your inference profile
#BEDROCK_MODEL_ID=amazon.nova-lite-v1:0
#BEDROCK_INFERENCE_PROFILE_ARN=arn:aws:bedrock:<region>:aws:inference-profile/amazon.nova-lite-v1:0

# Database and other settings are configured in Django settings;
# this example focuses on LLM provider configuration.
